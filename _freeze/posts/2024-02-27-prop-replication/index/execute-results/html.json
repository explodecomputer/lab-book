{
  "hash": "3fb8cba1468368dd636e099b34f6097d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Evaluating replication rates\"\nauthor: Gibran Hemani\ndate: \"2024-02-27\"\ncategories: []\n---\n\n\n## Background\n\nTaking a set of genetic effects in one study and replicating in another - what is the appropriate way to determine if the effects are consistent?\n\n\n## Simulation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(100)\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'dplyr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nsim <- function(n1, n2, nsnp, nflip=1, afshared=FALSE, bsd=1) {\n    # different allele frequencies per study\n    af1 <- runif(nsnp, 0.01, 0.99)\n    if(afshared) {\n        af2 <- af1\n    } else {\n        af2 <- runif(nsnp, 0.01, 0.99)\n    }\n\n    # identifical effect sizes across studies\n    b1 <- rnorm(nsnp, sd=bsd)\n    b2 <- b1\n\n    # make one of the effects different\n    if(nflip > 0) {\n        b1[1:nflip] <- b1[1:nflip] * -1\n    }\n\n    # Assume variance of trait is the same across studies\n    se1 <- 1 / sqrt(2 * af1 * (1-af1) * n1)\n    se2 <- 1 / sqrt(2 * af2 * (1-af2) * n2)\n\n    dat <- tibble(\n        af1, af2, b1, b2, se1, se2,\n        bhat1 = rnorm(nsnp, b1, se1),\n        bhat2 = rnorm(nsnp, b2, se2),\n        pval1 = 2 * pnorm(-abs(bhat1/se1)),\n        pval2 = 2 * pnorm(-abs(bhat2/se2)),\n        r21 = b1^2 * af1 * (1-af1) * 2,\n        r22 = b2^2 * af2 * (1-af2) * 2,\n    )\n    return(dat)\n}\n```\n:::\n\n\n## Plot relationship\n\nSimple trait, a few large effects\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_simple <- sim(\n    n1 = 100000, \n    n2 = 10000, \n    nsnp = 10,\n    nflip = 0, \n    afshared = TRUE, \n    bsd = sqrt(0.5)/10\n)\nggplot(dat_simple, aes(bhat1, bhat2)) +\ngeom_point() +\ngeom_errorbarh(aes(xmax = bhat1 + 1.96*se1, xmin = bhat1 - 1.96*se1)) +\ngeom_errorbar(aes(ymax = bhat2 + 1.96*se2, ymin = bhat2 - 1.96*se2)) +\ngeom_abline(intercept=0, slope=1) +\ngeom_smooth(method=\"lm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\nComplex trait with many small effects\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_complex <- sim(\n    n1 = 100000, \n    n2 = 10000, \n    nsnp = 1000,\n    nflip = 0, \n    afshared = TRUE, \n    bsd = sqrt(0.00008)\n)\ntable(dat_complex$pval1 < 5e-8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFALSE  TRUE \n  995     5 \n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(dat_complex, aes(bhat1, bhat2)) +\ngeom_point() +\ngeom_errorbarh(aes(xmax = bhat1 + 1.96*se1, xmin = bhat1 - 1.96*se1)) +\ngeom_errorbar(aes(ymax = bhat2 + 1.96*se2, ymin = bhat2 - 1.96*se2)) +\ngeom_abline(intercept=0, slope=1) +\ngeom_smooth(method=\"lm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n## Relationship between effect sizes\n\nExpect slope to be about 1 because the betas are the same across the two studies. But differences in power could distort this\n\nSlope in simple trait\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(bhat2 ~ bhat1, data=dat_simple))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = bhat2 ~ bhat1, data = dat_simple)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.010397 -0.006070 -0.002261  0.002275  0.029045 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.003745   0.003811  -0.983    0.355    \nbhat1        1.162936   0.104661  11.111 3.84e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.01204 on 8 degrees of freedom\nMultiple R-squared:  0.9391,\tAdjusted R-squared:  0.9315 \nF-statistic: 123.5 on 1 and 8 DF,  p-value: 3.845e-06\n```\n\n\n:::\n:::\n\n\nSlope in complex trait\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(bhat2 ~ bhat1, data=dat_complex))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = bhat2 ~ bhat1, data = dat_complex)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.112320 -0.012697 -0.000413  0.013574  0.128769 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.0001423  0.0007271  -0.196    0.845    \nbhat1        0.4467767  0.0646851   6.907 8.81e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02298 on 998 degrees of freedom\nMultiple R-squared:  0.04562,\tAdjusted R-squared:  0.04466 \nF-statistic: 47.71 on 1 and 998 DF,  p-value: 8.807e-12\n```\n\n\n:::\n:::\n\n\n\n## Replication rate\n\nExpect all significant assocs to replicate. But differences in power could distort this\n\nReplication rate in simple trait is 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_simple %>%\n    mutate(disc = pval1 < 5e-8, rep = disc & pval2 < 0.05) %>%\n    summarise(ndisc=sum(disc), nrep=sum(rep), rate=nrep/ndisc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  ndisc  nrep  rate\n  <int> <int> <dbl>\n1     4     4     1\n```\n\n\n:::\n:::\n\n\nReplication rate in complex trait is much lower\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_complex %>%\n    mutate(disc = pval1 < 5e-8, rep = disc & pval2 < 0.05) %>%\n    summarise(ndisc=sum(disc), nrep=sum(rep), rate=nrep/ndisc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  ndisc  nrep  rate\n  <int> <int> <dbl>\n1     5     2   0.4\n```\n\n\n:::\n:::\n\n\n## Expected vs observed replication rates\n\nWe can calculate the expected number to replicate given the differential power (due to sample size and allele frequency differences across studies), and compare this to the observed number to replicate. If fewer replicate than expected, then this is evidence of heterogeneity in the effect sizes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#' Estimate expected vs observed replication of effects between discovery and replication datasets\n#' \n#' Taken from Okbay et al 2016. Under the assumption that all discovery effects are unbiased, what fraction of associations would replicate in the replication dataset, given the differential power of the discovery and replication datasets.\n#' Uses standard error of the replication dataset to account for differences in sample size and distribution of independent variable\n#' \n#' @param b_disc Vector of discovery betas\n#' @param b_rep Vector of replication betas\n#' @param se_disc Vector of discovery standard errors\n#' @param se_rep Vector of replication standard errors\n#' @param alpha Nominal replication significance threshold\n#' \n#' @return List of results\n#' - res: aggregate expected replication rate vs observed replication rate\n#' - variants: per variant expected replication rates\nprop_overlap <- function(b_disc, b_rep, se_disc, se_rep, alpha) {\n  p_sign <- pnorm(-abs(b_disc) / se_disc) * pnorm(-abs(b_disc) / se_rep) + ((1 - pnorm(-abs(b_disc) / se_disc)) * (1 - pnorm(-abs(b_disc) / se_rep)))\n  p_sig <- pnorm(-abs(b_disc) / se_rep + qnorm(alpha / 2)) + (1 - pnorm(-abs(b_disc) / se_rep - qnorm(alpha / 2)))\n  p_rep <- pnorm(abs(b_rep) / se_rep, lower.tail = FALSE)\n  res <- tibble::tibble(\n    nsnp = length(b_disc),\n    metric = c(\"Sign\", \"Sign\", \"P-value\", \"P-value\"),\n    datum = c(\"Expected\", \"Observed\", \"Expected\", \"Observed\"),\n    value = c(sum(p_sign, na.rm = TRUE), sum(sign(b_disc) == sign(b_rep)), sum(p_sig, na.rm = TRUE), sum(p_rep < alpha, na.rm = TRUE))\n  ) %>%\n    dplyr::group_by(metric) %>%\n      dplyr::do({\n        x <- .\n        if(.$nsnp[1] > 0) {\n          bt <- binom.test(\n            x=.$value[.$datum == \"Observed\"], \n            n=.$nsnp[1], \n            p=.$value[.$datum == \"Expected\"] / .$nsnp[1]\n          )$p.value\n          x$pdiff <- bt\n        }\n        x\n      })\n  return(list(res = res, variants = dplyr::tibble(sig = p_sig, sign = p_sign, )))\n}\n```\n:::\n\n\n\nSimple trait\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(dat_simple %>% filter(pval1 < 5e-8), prop_overlap(bhat1, bhat2, se1, se2, 0.05))$res\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 5\n# Groups:   metric [2]\n   nsnp metric  datum    value pdiff\n  <int> <chr>   <chr>    <dbl> <dbl>\n1     4 P-value Expected  3.34     1\n2     4 P-value Observed  4        1\n3     4 Sign    Expected  3.99     1\n4     4 Sign    Observed  4        1\n```\n\n\n:::\n:::\n\n\nThis shows that we expect all significant discovery associations to replicate, and indeed they do.\n\nComplex trait\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(dat_complex %>% filter(pval1 < 5e-8), prop_overlap(bhat1, bhat2, se1, se2, 0.05))$res\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 5\n# Groups:   metric [2]\n   nsnp metric  datum    value pdiff\n  <int> <chr>   <chr>    <dbl> <dbl>\n1     5 P-value Expected  2.35     1\n2     5 P-value Observed  2        1\n3     5 Sign    Expected  4.85     1\n4     5 Sign    Observed  5        1\n```\n\n\n:::\n:::\n\n\nThis shows that we don't expect all significant discovery associations to replicate, and indeed they don't, but the rate of observed replication matches the expected rate of replication. The `pdiff` column is the p-value from a binomial test comparing the observed and expected replication rates, a low p-value indicates that the observed replication rate is substantially different from the expected replication rate.\n\n## Heterogeneity\n\nEvaluate if any one particular variant has heterogeneity in effect sizes across the two studies. This is done using Cochrane's Q statistic, which accounts for difference in power (based on SE) across the studies.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfixed_effects_meta_analysis <- function(beta_vec, se_vec) {\n    w <- 1 / se_vec^2\n    beta <- sum(beta_vec * w, na.rm=T) / sum(w, na.rm=T)\n    se <- sqrt(1 / sum(w, na.rm=T))\n    pval <- pnorm(abs(beta / se), lower.tail = FALSE)\n    Qj <- w * (beta-beta_vec)^2\n    Q <- sum(Qj, na.rm=T)\n    Qdf <- sum(!is.na(beta_vec))-1\n    if(Qdf == 0) Q <- 0\n    Qjpval <- pchisq(Qj, 1, lower.tail=FALSE)\n    Qpval <- pchisq(Q, Qdf, lower.tail=FALSE)\n    return(list(beta=beta, se=se, pval=pval, Q=Q, Qdf=Qdf, Qpval=Qpval, Qj=Qj, Qjpval=Qjpval))\n}\n```\n:::\n\n\nSimple trait, per-variant heterogeneity\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhet_simple <- lapply(1:nrow(dat_simple), \\(i) {\n    o <- fixed_effects_meta_analysis(c(dat_simple$bhat1[i], dat_simple$bhat2[i]), c(dat_simple$se1[i], dat_simple$se2[i]))\n    tibble(\n        SNP = i,\n        beta = o$beta,\n        se = o$se,\n        pval = o$pval,\n        Q = o$Q,\n        Qdf = o$Qdf,\n        Qpval = o$Qpval\n    )\n}) %>% bind_rows() %>%\n    mutate(Qfdr = p.adjust(Qpval, method=\"fdr\"))\n\nhet_simple\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 8\n     SNP     beta      se     pval       Q   Qdf Qpval  Qfdr\n   <int>    <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl> <dbl>\n 1     1  0.0218  0.00460 1.10e- 6 0.167       1 0.682 0.964\n 2     2 -0.0440  0.00485 5.52e-20 0.324       1 0.569 0.964\n 3     3  0.0529  0.00429 2.64e-35 0.00438     1 0.947 0.964\n 4     4 -0.0689  0.00863 7.30e-16 0.686       1 0.407 0.964\n 5     5 -0.0157  0.00427 1.17e- 4 0.213       1 0.645 0.964\n 6     6  0.00446 0.00427 1.48e- 1 0.00204     1 0.964 0.964\n 7     7  0.0136  0.00539 5.86e- 3 2.09        1 0.148 0.964\n 8     8 -0.0133  0.00441 1.24e- 3 0.0443      1 0.833 0.964\n 9     9  0.0553  0.00428 1.70e-38 0.115       1 0.734 0.964\n10    10  0.00322 0.00559 2.82e- 1 0.170       1 0.680 0.964\n```\n\n\n:::\n:::\n\n\nComplex trait, per variant heterogeneity\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhet_complex <- lapply(1:nrow(dat_complex), \\(i) {\n    o <- fixed_effects_meta_analysis(c(dat_complex$bhat1[i], dat_complex$bhat2[i]), c(dat_complex$se1[i], dat_complex$se2[i]))\n    tibble(\n        SNP = i,\n        beta = o$beta,\n        se = o$se,\n        pval = o$pval,\n        Q = o$Q,\n        Qdf = o$Qdf,\n        Qpval = o$Qpval\n    )\n}) %>% bind_rows() %>%\n    mutate(Qfdr = p.adjust(Qpval, method=\"fdr\"))\n\nhet_complex\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,000 × 8\n     SNP      beta      se    pval      Q   Qdf  Qpval  Qfdr\n   <int>     <dbl>   <dbl>   <dbl>  <dbl> <dbl>  <dbl> <dbl>\n 1     1 -0.00360  0.00433 0.203   1.10       1 0.295  0.934\n 2     2  0.00692  0.00453 0.0632  3.98       1 0.0460 0.867\n 3     3 -0.0110   0.00431 0.00536 0.0568     1 0.812  0.980\n 4     4  0.0233   0.0106  0.0138  0.0291     1 0.864  0.988\n 5     5  0.000229 0.00450 0.480   0.0512     1 0.821  0.981\n 6     6  0.000567 0.00440 0.449   0.0778     1 0.780  0.976\n 7     7 -0.0112   0.00596 0.0300  0.272      1 0.602  0.942\n 8     8 -0.000199 0.00506 0.484   0.440      1 0.507  0.934\n 9     9 -0.00530  0.00564 0.174   5.51       1 0.0189 0.767\n10    10  0.0129   0.00712 0.0351  0.502      1 0.478  0.934\n# ℹ 990 more rows\n```\n\n\n:::\n:::\n\n\nTry simulating where some of the effects are actually different\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_dif <- sim(\n    n1 = 100000, \n    n2 = 10000, \n    nsnp = 100,\n    nflip = 10, \n    afshared = FALSE, \n    bsd = sqrt(0.5)/10\n)\n```\n:::\n\n\nReplication rate estimate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprop_overlap(dat_dif$bhat1, dat_dif$bhat2, dat_dif$se1, dat_dif$se2, 0.05)$res\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 5\n# Groups:   metric [2]\n   nsnp metric  datum    value   pdiff\n  <int> <chr>   <chr>    <dbl>   <dbl>\n1   100 P-value Expected  60.6 0.838  \n2   100 P-value Observed  62   0.838  \n3   100 Sign    Expected  92.3 0.00462\n4   100 Sign    Observed  84   0.00462\n```\n\n\n:::\n:::\n\n\nIn this situation the effects have the same magnitude (so the p-values should give comparable estimates), but the signs are different for some of the effects. This is reflected in the observed replication rate for the sign, which is lower than the expected replication rate.\n\nHeterogeneity estimate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhet_dif <- lapply(1:nrow(dat_dif), \\(i) {\n    o <- fixed_effects_meta_analysis(c(dat_dif$bhat1[i], dat_dif$bhat2[i]), c(dat_dif$se1[i], dat_dif$se2[i]))\n    tibble(\n        SNP = i,\n        beta = o$beta,\n        se = o$se,\n        pval = o$pval,\n        Q = o$Q,\n        Qdf = o$Qdf,\n        Qpval = o$Qpval\n    )\n}) %>% bind_rows() %>%\n    mutate(Qfdr = p.adjust(Qpval, method=\"fdr\"))\nhet_dif %>% filter(Qfdr < 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 8\n     SNP    beta      se     pval      Q   Qdf    Qpval     Qfdr\n   <int>   <dbl>   <dbl>    <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n 1     2  0.0721 0.00668 2.11e-27  57.2      1 3.92e-14 1.31e-12\n 2     3 -0.0371 0.00744 3.10e- 7  54.5      1 1.56e-13 3.90e-12\n 3     4 -0.0635 0.00509 5.09e-36 118.       1 2.20e-27 1.10e-25\n 4     5 -0.0236 0.00638 1.12e- 4  14.3      1 1.53e- 4 1.92e- 3\n 5     6  0.0723 0.00573 7.14e-37  39.8      1 2.88e-10 4.80e- 9\n 6     7 -0.0410 0.00478 5.17e-18  31.3      1 2.16e- 8 3.08e- 7\n 7     8  0.0486 0.00870 1.18e- 8 154.       1 2.08e-35 2.08e-33\n 8     9  0.0274 0.00446 4.13e-10   8.72     1 3.14e- 3 3.14e- 2\n 9    10 -0.0339 0.00648 8.04e- 8  42.7      1 6.33e-11 1.27e- 9\n10    90 -0.0562 0.00776 2.22e-13  10.8      1 1.04e- 3 1.15e- 2\n```\n\n\n:::\n:::\n\n\nThis detects a heterogeneous effect.\n\n## Limitations\n\nNote that trying to replicate discovery SNPs can have problems because of winner's curse in the discovery estimate, which could lead to lower observed replication rates than expected even accounting for differences in power.\n\n## Summary\n\n- The regression of effects across studies might not be 1 even when the true effects are consistent across studies, because power differences can distort the relationship\n- Estimating the observed vs expected replication rates can help to identify if there are systematic differences in effect sizes across studies\n- Estimating the per-variant heterogeneity can estimate if there are any particular variants that have different effect sizes across studies\n\n---\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggplot2_3.4.2 dplyr_1.1.4  \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.4       nlme_3.1-163      cli_3.6.1         knitr_1.45       \n [5] rlang_1.1.2       xfun_0.41         generics_0.1.3    jsonlite_1.8.7   \n [9] labeling_0.4.2    glue_1.6.2        colorspace_2.1-0  htmltools_0.5.7  \n[13] scales_1.2.1      fansi_1.0.5       rmarkdown_2.25    grid_4.3.2       \n[17] munsell_0.5.0     evaluate_0.23     tibble_3.2.1      fastmap_1.1.1    \n[21] yaml_2.3.7        lifecycle_1.0.4   compiler_4.3.2    htmlwidgets_1.6.3\n[25] pkgconfig_2.0.3   mgcv_1.9-0        farver_2.1.1      lattice_0.21-9   \n[29] digest_0.6.33     R6_2.5.1          tidyselect_1.2.0  utf8_1.2.4       \n[33] splines_4.3.2     pillar_1.9.0      magrittr_2.0.3    Matrix_1.6-1.1   \n[37] withr_2.5.2       tools_4.3.2       gtable_0.3.3     \n```\n\n\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}