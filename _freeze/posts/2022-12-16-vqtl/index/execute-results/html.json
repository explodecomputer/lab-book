{
  "hash": "f0f71ec89201408feb2a7e054fabb0f0",
  "result": {
    "markdown": "---\ntitle: \"Inflation of vQTLs\"\nauthor: \"Gibran Hemani\"\nformat:\n  html:\n    self-contained: true\neditor: visual\nexecute:\n  cache: true\n---\n\n\n## Background\n\nThis paper describes how incomplete linkage disequilibrium can lead to inflated test statistics for interactions - https://www.nature.com/articles/s41586-021-03765-z. Because interaction terms contribute to variance heterogeneity across genotype classes, this could also inflate vQTL detection methods.\n\nExample model\n\nSuppose a system with three variants and one trait. The trait \\$x\\$ is influenced by a single additive causal variant \\$y_1\\$. But there is another variant in LD with this causal variant \\$y_2\\$. Finally, a third variant is independent of all other variables (think of that as a trans SNP). So\n\n\n$$\nx_i = y_{1,i} + e_i\n$$\n\n\nBut we test for an interaction between y_2 and y_3.\n\nRun some simulations...\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-1_7cd4ca94b2fd57a8af9e9a7a5d101abc'}\n\n```{.r .cell-code}\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'dplyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\nset.seed(12345)\n\ntest_drm <- function(g, y)\n{\n  y.i <- tapply(y, g, median, na.rm=T)  \n  z.ij <- abs(y - y.i[g+1])\n  summary(lm(z.ij ~ g))$coef %>%\n    as_tibble() %>%\n    slice(2) %>%\n    mutate(method=\"drm\")\n}\n\ncorrelated_binomial <- function (nid, p1, p2, rho, n = 2, round = TRUE, print = FALSE) \n{\n    p <- p1\n    q <- p2\n    a <- function(rho, p, q) {\n        rho * sqrt(p * q * (1 - p) * (1 - q)) + (1 - p) * (1 - \n            q)\n    }\n    a.0 <- a(rho, p, q)\n    prob <- c(`(0,0)` = a.0, `(1,0)` = 1 - q - a.0, `(0,1)` = 1 - \n        p - a.0, `(1,1)` = a.0 + p + q - 1)\n    if (min(prob) < 0) {\n        print(prob)\n        stop(\"Error: a probability is negative.\")\n    }\n    n.sim <- nid\n    u <- sample.int(4, n.sim * n, replace = TRUE, prob = prob)\n    y <- floor((u - 1)/2)\n    x <- 1 - u%%2\n    x <- colSums(matrix(x, nrow = n))\n    y <- colSums(matrix(y, nrow = n))\n    if (round) {\n        x <- round(x)\n        y <- round(y)\n    }\n    if (print) {\n        print(table(x, y))\n        print(stats::cor(x, y))\n    }\n    return(cbind(x, y))\n}\n\ngendatp <- function(n, p1, p2, p3, r1)\n{\n\tdat <- correlated_binomial(n, p1, p2, r1) %>% as_tibble()\n\tnames(dat) <- c(\"y1\", \"y2\")\n\tdat$y3 <- rbinom(n, 1, p3)\n\treturn(dat)\n}\n\nrun_simp <- function(param, i)\n{\n\tset.seed(i*10)\n\tdat <- gendatp(param$n[i], param$p1[i], param$p2[i], param$p3[i], param$r1[i])\n\tx <- dat$y1 + rnorm(nrow(dat), sd=sd(dat$y1)/4)\n\tmod1 <- lm(x ~ y2 + y3, dat)\n\tmod2 <- lm(x ~ y2 + y3 + y2*y3, dat)\n\tamod <- anova(mod1, mod2)\n\tparam$F[i] <- amod$P[2]\n\to1 <- test_drm(dat$y1, x)\n\to2 <- test_drm(dat$y2, x)\n\to3 <- test_drm(dat$y3, x)\n\tparam$drm1[i] <- o1$`Pr(>|t|)`\n\tparam$drm2[i] <- o2$`Pr(>|t|)`\n\tparam$drm3[i] <- o3$`Pr(>|t|)`\n\treturn(param[i,])\n}\n\nparam <- expand.grid(\n\tp1=0.1,\n\tp2=0.1,\n\tp3=0.5,\n\tp4=0.1,\n\tn=1000,\n\tr1=seq(0, 1, by=0.2),\n\tsim=1:500,\n\tr2=NA,\n\tF=NA,\n\tdrm1=NA,\n\tdrm2=NA,\n\tdrm3=NA\n)\n\nresp <- lapply(1:nrow(param), function(x) run_simp(param, x)) %>% bind_rows()\nstr(resp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t3000 obs. of  12 variables:\n $ p1  : num  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 ...\n $ p2  : num  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 ...\n $ p3  : num  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ...\n $ p4  : num  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 ...\n $ n   : num  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...\n $ r1  : num  0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 ...\n $ sim : int  1 1 1 1 1 1 2 2 2 2 ...\n $ r2  : logi  NA NA NA NA NA NA ...\n $ F   : num  0.4136 0.0371 0.0567 0.5604 0.0364 ...\n $ drm1: num  0.288 0.376 0.16 0.215 0.998 ...\n $ drm2: num  1.64e-02 3.88e-17 1.58e-25 2.64e-26 9.41e-19 ...\n $ drm3: num  0.9178 0.1475 0.0181 0.1416 0.7348 ...\n - attr(*, \"out.attrs\")=List of 2\n  ..$ dim     : Named int [1:12] 1 1 1 1 1 6 500 1 1 1 ...\n  .. ..- attr(*, \"names\")= chr [1:12] \"p1\" \"p2\" \"p3\" \"p4\" ...\n  ..$ dimnames:List of 12\n  .. ..$ p1  : chr \"p1=0.1\"\n  .. ..$ p2  : chr \"p2=0.1\"\n  .. ..$ p3  : chr \"p3=0.5\"\n  .. ..$ p4  : chr \"p4=0.1\"\n  .. ..$ n   : chr \"n=1000\"\n  .. ..$ r1  : chr [1:6] \"r1=0.0\" \"r1=0.2\" \"r1=0.4\" \"r1=0.6\" ...\n  .. ..$ sim : chr [1:500] \"sim=  1\" \"sim=  2\" \"sim=  3\" \"sim=  4\" ...\n  .. ..$ r2  : chr \"r2=NA\"\n  .. ..$ F   : chr \"F=NA\"\n  .. ..$ drm1: chr \"drm1=NA\"\n  .. ..$ drm2: chr \"drm2=NA\"\n  .. ..$ drm3: chr \"drm3=NA\"\n```\n:::\n:::\n\n\n## Type 1 error of vQTLs\n\nThis is what happens to the genetic interaction between y_2 and y_3 - remember that neither of these have a causal effect, and there is no interaction term, however y_2 is correlated with the causal variant y_1\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-2_f2e111432ff52b3b2a4997188881bde9'}\n\n```{.r .cell-code}\nggplot(resp, aes(x=as.factor(r1), y=-log10(F))) +\ngeom_boxplot() +\ngeom_hline(yintercept=-log10(0.05/nrow(resp))) +\nscale_fill_brewer(type=\"seq\") +\nlabs(y=\"Interaction -log10 p for y2xy3\", x=\"LD between tagging\\nvariant and causal variant\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nSo you get some false positives even after bonferroni correction. However now look at what happens to the variance QTL estimate for y_2 (the SNP that has no interaction but is in incomplete LD with the additive SNP y_1). Here we'll use the DRM method to test for vQTL effects at y_2\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-3_4f18f64acc3aa337eb6598ab07d89bff'}\n\n```{.r .cell-code}\nggplot(resp, aes(x=r1, y=-log10(drm2))) +\ngeom_boxplot(aes(fill=as.factor(r1))) +\nscale_fill_brewer(type=\"seq\") +\nlabs(y=\"DRM -log10 p\", x=\"LD between tagging\\nvariant and causal variant\", fill=\"\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nThis is really extreme type 1 sensitivity to incomplete LD. There's no problem at the actual causal locus (y_1)\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-4_9213f9c00be852e9afad0c7e8a2092ae'}\n\n```{.r .cell-code}\nggplot(resp, aes(x=r1, y=-log10(drm1))) +\ngeom_boxplot(aes(fill=as.factor(r1))) +\nscale_fill_brewer(type=\"seq\") +\nlabs(y=\"DRM -log10 p\", x=\"LD between tagging\\nvariant and causal variant\", fill=\"\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nOr at the unlinked locus y_3\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-5_0f66fc42579ec1de08480b97a7ced76d'}\n\n```{.r .cell-code}\nggplot(resp, aes(x=r1, y=-log10(drm3))) +\ngeom_boxplot(aes(fill=as.factor(r1))) +\nscale_fill_brewer(type=\"seq\") +\nlabs(y=\"DRM -log10 p\", x=\"LD between tagging\\nvariant and causal variant\", fill=\"\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nImplications - performing an exhaustive search is going to give quite problematic results if the main effects aren't controlled. So you'd really have to know what all the main effects are before performing the vQTL tests in order to control for them. Note that incomplete control of the main effects is inevitable and we should be anticipating elevated type 1 error rates for any SNPs that are in the region of any large main effects.\n\n## Power issues when controlling for main effects\n\nThe other problem is actually controlling for main effects. Suppose that a probe has two distal SNPs that interact e.g.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-6_4b947b26aa55e95a6e50a258a84865b6'}\n\n```{.r .cell-code}\nn <- 10000\ng1 <- rbinom(n, 2, 0.4)\ng2 <- rbinom(n, 2, 0.4)\ny <- g1 + g2 + g1 * g2 + rnorm(n, sd=1.5)\ntest_drm(g1, y) %>% str\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntibble [1 × 5] (S3: tbl_df/tbl/data.frame)\n $ Estimate  : num 0.362\n $ Std. Error: num 0.0173\n $ t value   : num 20.9\n $ Pr(>|t|)  : num 3.16e-95\n $ method    : chr \"drm\"\n```\n:::\n:::\n\n\nThe DRM method finds a big vQTL effect here because of the GxG interaction - so it's detecting that g1 might be interacting with something.\n\nIf we adjust for the main effects of g1 and g2 now look at DRM\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-7_4aad84578c00e818844cb58d8ff2cac8'}\n\n```{.r .cell-code}\nyres <- residuals(lm(y ~ g1 + g2))\ntest_drm(g1, yres) %>% str\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntibble [1 × 5] (S3: tbl_df/tbl/data.frame)\n $ Estimate  : num 0.0194\n $ Std. Error: num 0.0138\n $ t value   : num 1.4\n $ Pr(>|t|)  : num 0.161\n $ method    : chr \"drm\"\n```\n:::\n:::\n\n\nThe test statistic for the interaction test has massively attenuated.\n\nWhere does this leave us?\n\n-   If a SNP is a known additive causal variant then it is relatively safe from type 1 error\n\n-   If a SNP is not a known additive causal variant, then it is susceptible to type 1 error due to incomplete LD with actual additive causal variants\n\n-   If we adjust the probe for additive causal variants before testing the SNP, we risk drastically reducing the vQTL effect that arise due to GxG interactions\n\n-   Note that this applies to GxE for when adjusting for other covariates too - e.g. if we adjust probes for smoking, age, sex, cell type etc and we are trying to find interactions with those based on vQTLs then the power to identify those vQTL effects drastically reduces\n\n## Power of vQTL vs interaction\n\nSuppose we simulate a GxE interaction. We can try to detect it either using a vQTL method (e.g. DRM) or using a direct interaction test.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-8_47c71e8fafbc3b734daa89ad16221afe'}\n\n```{.r .cell-code}\nsim_gxe <- function(n, p, bi)\n{\n  params <- environment() %>% as.list() %>% as_tibble()\n  g <- rbinom(n, 2, p)\n  e <- rnorm(n)\n  y <- g + bi * g*e + e + rnorm(n)\n  \n  bind_rows(\n    test_drm(g, y),\n    summary(lm(y ~ g*e))$coef %>%\n      as_tibble() %>%\n      slice(n=4) %>%\n      mutate(method=\"interaction\")\n  ) %>%\n    bind_cols(., params)\n}\n\nparam <- expand.grid(\n  n=1000,\n  bi=seq(0,1,by=0.01),\n  nsim=10,\n  p=0.5\n) %>% select(-nsim)\nres <- lapply(1:nrow(param), function(i) do.call(sim_gxe, param[i,])) %>% bind_rows()\nres %>%\n  ggplot(., aes(x=bi, y=-log10(`Pr(>|t|)`))) +\n  geom_point(aes(colour=method))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nThe direct interaction test seems much better powered to detect these associations.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}