{
  "hash": "79be6dfc8d501f572bfbe929677b75e6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Approx matrix inverse\"\nauthor: Gibran Hemani\ndate: \"2024-09-07\"\ncategories: []\nexecute: \n  eval: false\n---\n\n\n## Background\n\nImprove matrix inversion speed by approximating using eigendecomposition\n\n```python\ndef approx_inverse(A, k):\n    # Compute eigenvalues and eigenvectors\n    eigenvalues, eigenvectors = np.linalg.eig(A)\n    \n    # Sort eigenvalues and eigenvectors\n    idx = eigenvalues.argsort()[::-1]\n    eigenvalues = eigenvalues[idx]\n    eigenvectors = eigenvectors[:, idx]\n    \n    # Select top k eigenvalues and eigenvectors\n    eigenvalues_k = eigenvalues[:k]\n    eigenvectors_k = eigenvectors[:, :k]\n    \n    # Compute approximate inverse\n    inv_eigenvalues_k = 1 / eigenvalues_k\n    approx_inv = eigenvectors_k @ np.diag(inv_eigenvalues_k) @ eigenvectors_k.T\n    \n    return approx_inv\n```\n\n\n::: {.cell}\n\n```{.r .cell-code}\napprox_inverse <- function(A, k) {\n  # Compute eigenvalues and eigenvectors\n  eig <- eigen(A)\n  \n  # Sort eigenvalues and eigenvectors\n  idx <- order(eig$values, decreasing = TRUE)\n  eigenvalues <- eig$values[idx]\n  eigenvectors <- eig$vectors[, idx]\n  \n  # Select top k eigenvalues and eigenvectors\n  eigenvalues_k <- eigenvalues[1:k]\n  eigenvectors_k <- eigenvectors[, 1:k]\n  \n  # Compute approximate inverse\n  inv_eigenvalues_k <- 1 / eigenvalues_k\n  approx_inv <- eigenvectors_k %*% diag(inv_eigenvalues_k) %*% t(eigenvectors_k)\n  \n  return(approx_inv)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsim_mat <- function(n) {\n  p <- qr.Q(qr(matrix(rnorm(n^2), n)))\n  Sigma <- crossprod(p, p*(n:1))\n  return(Sigma)\n}\nsim_mat(100)[1:10,1:10]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nSigma <- sim_mat(2000)\nSigma.inv <- solve(Sigma)\nSigma.inv.approx <- approx_inverse(Sigma, 10)\na <- eigen(Sigma)\ncor(c(Sigma.inv), c(Sigma.inv.approx))\nplot(c(Sigma.inv), c(Sigma.inv.approx))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"microbenchmark\")\nlibrary(microbenchmark)\nlibrary(dplyr)\n\nfn1 <- function(n, approx) {\n    Sigma <- sim_mat(n)\n    t1 <- Sys.time()\n    Sigma.inv <- solve(Sigma)\n    t1 <- Sys.time() - t1\n    t2 <- Sys.time()\n    Sigma.inv.approx <- approx_inverse(Sigma, approx)\n    t2 <- Sys.time() - t2\n    a <- cor(c(Sigma.inv), c(Sigma.inv.approx))\n    tibble(cor=a, k=approx, time1=t1, time2=t2)\n}\n\nfn1(1000, 10)\n\n\nmicrobenchmark()\n\n\nparam <- expand.grid(\n    n = \n)\n```\n:::\n\n\n\nEigendecomposition is the slow part. What about if we do eigendecomposition once and \n\n\n## \n\n\n::: {.cell}\n\n```{.r .cell-code}\nA <- sim_mat(2000)\n\neig <- eigen(A)\n\nAinv <- solve(A)\nAinv2 <- eig$vectors %*% diag(1/eig$values) %*% t(eig$vectors)\n\ncor(c(Ainv), c(Ainv2))\n\ni <- sample(1:2000, 400)\n\nAinvs <- solve(A[i, i])\nAinv2s <- eig$vectors[i,] %*% diag(1/eig$values) %*% t(eig$vectors[i,])\n\ncor(c(Ainvs), c(Ainv2s))\n\nplot(c(Ainvs), c(Ainv2s))\n\nplot(c(Ainv), c(Ainv2))\n\n\n\n\n\n\n\n# Sort eigenvalues and eigenvectors\nidx <- order(eig$values, decreasing = TRUE)\neigenvalues <- eig$values[idx]\neigenvectors <- eig$vectors[, idx]\n\n# Select top k eigenvalues and eigenvectors\neigenvalues_k <- eigenvalues[1:k]\neigenvectors_k <- eigenvectors[, 1:k]\n\n# Compute approximate inverse\ninv_eigenvalues_k <- 1 / eigenvalues_k\napprox_inv <- eigenvectors_k %*% diag(inv_eigenvalues_k) %*% t(eigenvectors_k)\n\nreturn(approx_inv)\n```\n:::\n\n\n\n\n---\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}