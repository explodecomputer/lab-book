{
  "hash": "0df89b2c9c0456f9e739de00136756fa",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Survival analysis using factoral MR\"\nauthor: Gibran Hemani, David Carslake\ndate: \"2025-12-19\"\ncategories: []\n---\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'dplyr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(simsurv)\nlibrary(survival)\nlibrary(boot)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'boot'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:survival':\n\n    aml\n```\n\n\n:::\n\n```{.r .cell-code}\nset.seed(123)\n```\n:::\n\n\n\n## Manually estimating power\n\nSuppose I want to know the power of a linear regression model through simulation. Generate simulated data to match what I see in my real analysis - the data generating model (DGM)\n\n- Here we have a variable x and y, both have variance of 1\n- There is some sample size n\n- But I don't know the effect size of x on y\n- I will be varying the effect size (beta) to see how it affects power\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndgm <- function(n = 30, beta = 0.2) {\n  x <- rnorm(n)\n  # We want the variance of y to be 1, so we just add enough noise on top of x*beta\n  y <- beta * x + rnorm(n, sd = sqrt(1 - beta^2))\n  tibble(x = x, y = y)\n}\n```\n:::\n\n\n\nNow that I've generated the data to mimic my real analysis, I need\nto estimate the effect of x on y in the same way that I would in the real analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimation <- function(data) {\n  model <- lm(y ~ x, data = data)\n  summary(model)$coefficients[2, 4]  # p-value for the slope\n}\n```\n:::\n\n\n\nFinally, I need to run this across lots of different potential values of beta and n, to see the average power.\n\nPower depends on the significance threshold (alpha). If I simulate a null where beta = 0, then I want power to equal the significance threshold\n\n\n::: {.cell}\n\n```{.r .cell-code}\npower_simulation <- function(nsim = 1000, n = c(30, 50, 70), beta = c(0, 0.2, 0.4), alpha = 0.05) {\n    params <- expand.grid(n = n, beta = beta, sim=1:nsim)\n    for(i in 1:nrow(params)) {\n        data <- dgm(n = params$n[i], beta = params$beta[i])\n        params$p_value[i] <- estimation(data)\n    }\n    # Count how many significant results we get for each combination of n and beta\n    # Divide by nsim to get the proportion of significant results (i.e., power)\n    params <- params %>%\n        group_by(n, beta) %>%\n        summarise(power = mean(p_value < alpha)) %>%\n        ungroup()\n    return(params)    \n}\n```\n:::\n\n\n\nTry out the dgm function\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- dgm(n = 5000, beta = 0.3)\nestimation(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.028908e-99\n```\n\n\n:::\n:::\n\n\nRun the power simulation just for beta = 0\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults <- power_simulation(nsim = 10000, n = c(500), beta = c(0), alpha = 0.05)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'n'. You can override using the `.groups`\nargument.\n```\n\n\n:::\n\n```{.r .cell-code}\nresults\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 3\n      n  beta  power\n  <dbl> <dbl>  <dbl>\n1   500     0 0.0512\n```\n\n\n:::\n:::\n\n\nSo power is roughly the same as alpha (0.05), that's good. Can generate power curves for varying n and beta\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults <- power_simulation(nsim = 500, n = c(50, 70, 90), beta = c(0, 0.3, 0.6, 0.9), alpha = 0.05)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'n'. You can override using the `.groups`\nargument.\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(results, aes(x = beta, y = power, color = factor(n))) +\n    geom_line() +\n    geom_point() +\n    labs(title = \"Power Simulation Results\",\n         x = \"Effect Size (Beta)\",\n         y = \"Power\",\n         color = \"Sample Size (n)\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n## Survival and factoral MR\n\nFrom this we can see the basic framework of a power simulation. Now we have to adapt it for factorial MR in cancer survival.\n\nThat means the dgm function needs to generate \n\n- genotype\n- proteomic\n- time to event\n\nAnd the estimation function needs to run a factorial MR analysis on time to event\n\nFor the time to event part, we can simulate the data using the simsurv package. First generate the protein levels and their interaction\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 10000\ng1 <- rbinom(n, 2, 0.3)  # genotype for protein 1\ng2 <- rbinom(n, 2, 0.4)  # genotype for protein 2\nu <- rnorm(n)          # unmeasured confounder\npred1 <-  0.5 * g1 + 0.3 * u\npred2 <-  0.5 * g2 + 0.3 * u\n\ncovars <- tibble(protein1 = pred1 + rnorm(n, sd = sqrt(1 - var(pred1))),\n                 protein2 = pred2 + rnorm(n, sd = sqrt(1 - var(pred2))),\n                 interaction = protein1 * protein2)\n\n# we'll need the shape and scale parameters for the Weibull distribution - you can get these from fitting a Weibull model to real data. e.g.\nlambdas <- 1.5\ngammas <- 0.01\n\n# And now we select some hypothesised betas for the proteins and their interaction\nbetas <- c(protein1 = 0.3, protein2 = 0.4, interaction = 0.2)\n\n# Finally we need a max time for the simulation. This will introduce right-censoring e.g.\nmaxt <- 5\n\nsimdata <- simsurv(lambdas = lambdas,\n                   gammas = gammas,\n                   betas = betas,\n                   x = covars,\n                   maxt = maxt)\n\nhead(simdata)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  id     eventtime status\n1  1 3.644299e-139      1\n2  2  1.879845e-72      1\n3  3  5.000000e+00      0\n4  4 9.135763e-104      1\n5  5  4.399160e-66      1\n6  6  6.818174e-84      1\n```\n\n\n:::\n:::\n\n\nThis gives the time to event and the outcome.\n\nFor estimation part, if this was just an observational analysis we could use the survival package to fit a Cox proportional hazards model using the `survival` package. For example: \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncox_model <- coxph(Surv(eventtime, status) ~ protein1 + protein2 + interaction, data = merge(covars, simdata, by = \"row.names\"))\nsummary(cox_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\ncoxph(formula = Surv(eventtime, status) ~ protein1 + protein2 + \n    interaction, data = merge(covars, simdata, by = \"row.names\"))\n\n  n= 10000, number of events= 8239 \n\n               coef exp(coef) se(coef)      z Pr(>|z|)    \nprotein1    0.21185   1.23596  0.01247 16.986   <2e-16 ***\nprotein2    0.27781   1.32024  0.01182 23.503   <2e-16 ***\ninteraction 0.01703   1.01718  0.01048  1.626    0.104    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n            exp(coef) exp(-coef) lower .95 upper .95\nprotein1        1.236     0.8091    1.2061     1.267\nprotein2        1.320     0.7574    1.2900     1.351\ninteraction     1.017     0.9831    0.9965     1.038\n\nConcordance= 0.743  (se = 0.005 )\nLikelihood ratio test= 1105  on 3 df,   p=<2e-16\nWald test            = 1135  on 3 df,   p=<2e-16\nScore (logrank) test = 1171  on 3 df,   p=<2e-16\n```\n\n\n:::\n:::\n\n\n\nBut as this is a factorial MR, we will need to use the genetic predictors of protein1, protein2 and the interaction.\n\n- First stage: regress protein1 and protein2 on their respective genotypes to get predicted values\n- Second stage: fit a Cox model using the predicted values and their interaction\n- Finally, bootstrap the interaction coefficients to get the correct p-value (use the SD(betas) as the standard error to get the p-values)\n\n\n::: {.cell}\n\n```{.r .cell-code}\niv_coxph <- function(data, ind=1:nrow(data)) {\n  d <- data[ind, ]\n  \n  m1 <- lm(protein1 ~ g1 + g2 + g1:g2, data = d)\n  d$res1 <- residuals(m1)\n  \n  m2 <- lm(protein2 ~ g1 + g2 + g1:g2, data = d)\n  d$res2 <- residuals(m2)\n  \n  fit_cox <- coxph(Surv(eventtime, status) ~ protein1 * protein2 + res1 + res2, data = d)\n  return(summary(fit_cox)$coefficients[\"protein1:protein2\", 1])  # return the beta for the interaction term\n}\n\nestimation <- function(data) {\n  bootres <- boot(data = data, statistic = iv_coxph, R=100)\n  sd_boot <- sd(bootres$t)\n  pval <- 2 * (1 - pnorm(abs(bootres$t0 / sd_boot)))\n  return(pval)\n}\n```\n:::\n\n\n\nSo overall the power simulation framework will be similar to the linear regression example, but with a more complex dgm and estimation function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndgm <- function(n = 1000, freq1, freq2, rsq_g1p1, rsq_g2p2, beta_p1, beta_p2, beta_interaction, beta_u, lambdas, gammas, maxt) {\n  g1 <- rbinom(n, 2, freq1)  # genotype for protein 1\n  g2 <- rbinom(n, 2, freq2)  # genotype for protein 2\n  u <- rnorm(n)              # unmeasured confounder that induces correlation between protein 1 and 2\n  pred1 <-  scale(g1) * rsq_g1p1 + beta_u * u\n  pred2 <-  scale(g2) * rsq_g2p2 + beta_u * u\n  \n  covars <- tibble(protein1 = pred1 + rnorm(n, sd = sqrt(1 - var(pred1))),\n                   protein2 = pred2 + rnorm(n, sd = sqrt(1 - var(pred2))),\n                   interaction = protein1 * protein2)\n    \n  betas <- c(protein1 = beta_p1, protein2 = beta_p2, interaction = beta_interaction)  \n  simdata <- simsurv(lambdas = lambdas,\n                     gammas = gammas,\n                     betas = betas,\n                     x = covars,\n                     maxt = maxt)\n  \n  d <- cbind(covars, simdata, g1, g2) %>% as_tibble()\n  return(d)\n}\n```\n:::\n\n\nNote that there's quite a lot of parameters that could vary in the dgm, but you could fix many of those cos you know what they are in the real data (e.g. n, freq1, freq2, rsq, beta_p1, beta_p2, lambdas, gammas, maxt values). So you'd end up varying the beta_interaction values and beta_u values only\n\nExample:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- dgm(n = 1000, freq1 = 0.3, freq2 = 0.4, rsq_g1p1 = 0.1, rsq_g2p2 = 0.1,\n         beta_p1 = 0.3, beta_p2 = 0.4, beta_interaction = 0.2, beta_u = 0.3,\n         lambdas = 1.5, gammas = 0.01, maxt = 5)\n\nestimation(d)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.353894\n```\n\n\n:::\n:::\n\n\nAnd wrap this into the power simulation function as before...\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}